{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Outcome of Bank Marketing\n",
    "## Author: Bryan Flood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Provide functions for cleaning and saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_query_data(dataset):\n",
    "    # Drop Unnecessary Columns \n",
    "    temp_dataset = dataset.drop('contact', axis=1)\n",
    "    temp_dataset = temp_dataset.drop('marital', axis=1)\n",
    "    temp_dataset = temp_dataset.drop('poutcome', axis=1)\n",
    "    \n",
    "    # Consolidate Unknown Values\n",
    "    temp_dataset[['job', 'education']] = temp_dataset[['job', 'education']].replace(['unknown'], 'other')\n",
    "    \n",
    "    # Create Dummy Variables\n",
    "    temp_dataset = pd.get_dummies(temp_dataset, columns = ['job'])\n",
    "    temp_dataset = pd.get_dummies(temp_dataset, columns = ['education'])\n",
    "    temp_dataset = pd.get_dummies(temp_dataset, columns = ['month'])\n",
    "\n",
    "    # Convert to numerical\n",
    "    temp_dataset['deposit'] = temp_dataset['deposit'].map({'yes': 1, 'no': 0})\n",
    "    temp_dataset['housing'] = temp_dataset['housing'].map({'yes': 1, 'no': 0})\n",
    "    temp_dataset['default'] = temp_dataset['default'].map({'yes': 1, 'no': 0})\n",
    "    temp_dataset['loan'] = temp_dataset['loan'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "    return temp_dataset\n",
    "\n",
    "def clean_training_data(dataset):\n",
    "    # Drop Unnecessary Columns + Rows \n",
    "    temp_dataset = dataset.drop(dataset[dataset.poutcome=='other'].index, axis = 0, inplace = False)\n",
    "    return clean_query_data(temp_dataset)\n",
    "\n",
    "\n",
    "\n",
    "def save_predictions(predictions):\n",
    "    string = \"\"\n",
    "    for counter, value in enumerate(predictions):\n",
    "        string += f\"TEST{counter+1},\"\n",
    "        if(value):\n",
    "            string+=\"yes\\n\"\n",
    "        else:\n",
    "            string+=\"no\\n\"\n",
    "\n",
    "    csv_file = open(\"./data/predictions.csv\", \"w\")\n",
    "    csv_file.write(string)\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in and Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['id',\n",
    "                 'age',\n",
    "                 'job',\n",
    "                 'marital',\n",
    "                 'education',\n",
    "                 'default',\n",
    "                 'balance',\n",
    "                 'housing',\n",
    "                 'loan',\n",
    "                 'contact',\n",
    "                 'day',\n",
    "                 'month',\n",
    "                 'duration',\n",
    "                 'campaign',\n",
    "                 'previous',\n",
    "                 'poutcome',\n",
    "                 'deposit']\n",
    "\n",
    "# Load in trainingset\n",
    "dataset = pd.read_csv(\"./data/trainingset.csv\",\n",
    "                          sep=',',\n",
    "                          names=feature_names)\n",
    "dataset = dataset.drop(columns=\"id\")\n",
    "\n",
    "# Load in query set\n",
    "query_set = pd.read_csv(\"./data/queries.csv\",\n",
    "                          sep=',',\n",
    "                          names=feature_names)\n",
    "query_set = query_set.drop(columns=\"id\")\n",
    "\n",
    "\n",
    "# Clean training set\n",
    "temp_dataset = clean_training_data(dataset)\n",
    "\n",
    "\n",
    "# Clean query set\n",
    "query_set = clean_query_data(query_set)\n",
    "\n",
    "\n",
    "# Features\n",
    "features = temp_dataset.drop(columns=\"deposit\")\n",
    "\n",
    "# Target\n",
    "target = temp_dataset['deposit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Ratio 0.5\n",
      "Accuracy Score of: 0.8266986959505834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "split= 0.50\n",
    "seed_value = 8\n",
    "features_train, features_test, target_train, target_test= train_test_split(features, target, test_size=split, random_state=seed_value)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "decision_tree.fit(features_train, target_train)\n",
    "\n",
    "predictions = decision_tree.predict(features_test)\n",
    "print(f\"Test Ratio {split}\")\n",
    "print(f\"Accuracy Score of: {accuracy_score(target_test, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Actual Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_set = query_set.drop(columns=\"deposit\")\n",
    "\n",
    "predictions = decision_tree.predict(query_set)\n",
    "\n",
    "save_predictions(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "## How the problem was solved\n",
    "### 1. Data\n",
    "There were a few issues with the data.\n",
    "Previous and Balance had 19752 (81.3%) and 1890 (7.8%) zero values respectively.\n",
    "\n",
    "The target variable skews heavily towards no occurring 88.4% of the time.\n",
    "We have to assume that the training data is representative of the whole dataset and query set.\n",
    "Without the actual results of the query set all testing had to be done on the training set.\n",
    "\n",
    "I found a lot of the rows and columns weren't that useful and ended up dropping them.\n",
    "I consolidated the different types of unknown values.\n",
    "I lastly converted the binary string columns to be binary storing 1s and 0s.\n",
    "I found good performance with the rest as dummy variables as they all have a distance-based relationship for their values.\n",
    "\n",
    "I considered using more advanced techniques for cleaning that took into consideration the standard deviation and similar metrics. I decided against it due to my correlation findings. Most of the different formulas for detecting correlations found nothing between deposit and the other columns.\n",
    "Using Phi k Correlation, I was able to see that month and campaign had the most influence by far on predicting the deposit value\n",
    "\n",
    "\n",
    "### 2. Classifier\n",
    "For the classifier I used sklearn's DecisionTreeClassifier.\n",
    "After I had completed a quick clean of the data, I tested the data on variety of different classifiers provided by SKLearn and the decision tree solution gave consistently better results regardless of the split of data.\n",
    "\n",
    "One of the biggest issues with decision tree's how easy they are to be overfitted. In our case I believed this to be not much of an issue as the data is so skewed (88.4%) towards no deposit.\n",
    "\n",
    "\n",
    "### 3. Testing\n",
    "For testing I used a train and test split of the training data.\n",
    "I used a wide variety of ratios and seed values to ensure accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}